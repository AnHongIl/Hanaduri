{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from konlpy.tag import Mecab\n",
    "import csv\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    row[0] : no\n",
    "    row[1] : category\n",
    "    row[2] : title\n",
    "    row[3] : body\n",
    "\"\"\"\n",
    "numbers = []\n",
    "categories = []\n",
    "titles = []\n",
    "contents = []\n",
    "with open('input_11829.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        numbers.append(row[0])\n",
    "        categories.append(row[1])\n",
    "        titles.append(row[2])\n",
    "        contents.append(row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract nouns through Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mecab = Mecab('/usr/local/lib/mecab/dic/mecab-ko-dic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(titles):\n",
    "    titles[i] = mecab.nouns(title)\n",
    "    \n",
    "for i, content in enumerate(contents):\n",
    "    contents[i] = mecab.nouns(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    for word in title:\n",
    "        words_counts[word] += 1\n",
    "for content in contents:\n",
    "    for word in content:\n",
    "        words_counts[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29861\n"
     ]
    }
   ],
   "source": [
    "words = set(words_counts.keys())\n",
    "words_size = len(words)\n",
    "print(words_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'캠코더': 0,\n",
       " '난봉': 1,\n",
       " '市': 2,\n",
       " '란트': 3,\n",
       " '철광석': 4,\n",
       " '즉석': 5,\n",
       " '사신': 6,\n",
       " '전작': 7,\n",
       " '아군': 8,\n",
       " '사별': 9,\n",
       " '지아비': 10,\n",
       " '련지': 11,\n",
       " '허주원': 12,\n",
       " '전대미문': 13,\n",
       " '설치목': 14,\n",
       " '치욕': 15,\n",
       " '비비에스': 16,\n",
       " '쿠키': 17,\n",
       " '그레': 18,\n",
       " '여알': 19,\n",
       " '왠': 20,\n",
       " '작가': 21,\n",
       " '은퇴': 22,\n",
       " '해골바가지': 23,\n",
       " '돈장사': 24,\n",
       " '강도지': 25,\n",
       " '연근': 26,\n",
       " '경각심': 27,\n",
       " '신세계': 28,\n",
       " '융자': 29,\n",
       " '침투': 30,\n",
       " '성폭행': 31,\n",
       " '옵션': 32,\n",
       " '청도군': 33,\n",
       " '기아차': 34,\n",
       " '과중': 35,\n",
       " '반납': 36,\n",
       " '양법': 37,\n",
       " '저수지': 38,\n",
       " '인지': 39,\n",
       " '時': 40,\n",
       " '품귀': 41,\n",
       " '甲': 42,\n",
       " '김태현': 43,\n",
       " '미어': 44,\n",
       " '등반': 45,\n",
       " '보릿자루': 46,\n",
       " '단두대': 47,\n",
       " '말벌': 48,\n",
       " '가름길': 49,\n",
       " '취미': 50,\n",
       " '나경원': 51,\n",
       " '공세동': 52,\n",
       " '지주': 53,\n",
       " '강단': 54,\n",
       " '피해자': 55,\n",
       " '밑줄': 56,\n",
       " '동포': 57,\n",
       " '갈림길': 58,\n",
       " '기하급수': 59,\n",
       " '상부상조': 60,\n",
       " '조혜련': 61,\n",
       " '철창': 62,\n",
       " '편차': 63,\n",
       " '산품': 64,\n",
       " '남일': 65,\n",
       " '으': 66,\n",
       " '네다섯': 67,\n",
       " '달팽이': 68,\n",
       " '맏사위': 69,\n",
       " '후배': 70,\n",
       " '저층': 71,\n",
       " '주택기금': 72,\n",
       " '한상': 73,\n",
       " '폐경기': 74,\n",
       " '센텀': 75,\n",
       " '나름': 76,\n",
       " '자기계': 77,\n",
       " '병충': 78,\n",
       " '구전': 79,\n",
       " '화요일': 80,\n",
       " '킹': 81,\n",
       " '이분': 82,\n",
       " '국민학생': 83,\n",
       " '현물': 84,\n",
       " '아이스': 85,\n",
       " '전처': 86,\n",
       " '레토': 87,\n",
       " '손실금': 88,\n",
       " '서초대로': 89,\n",
       " '천사': 90,\n",
       " '꽹과리': 91,\n",
       " '아달라': 92,\n",
       " '부정승차': 93,\n",
       " '규합': 94,\n",
       " '부료': 95,\n",
       " '우든': 96,\n",
       " '응양': 97,\n",
       " '내참': 98,\n",
       " '불인': 99,\n",
       " '유격전': 100,\n",
       " '철조망': 101,\n",
       " '공명심': 102,\n",
       " '정보통': 103,\n",
       " '무신경': 104,\n",
       " '경산시': 105,\n",
       " '기여': 106,\n",
       " '편입학': 107,\n",
       " '룸서비스': 108,\n",
       " '골대': 109,\n",
       " '숟가락': 110,\n",
       " '엽기': 111,\n",
       " '조포': 112,\n",
       " '환인': 113,\n",
       " '퇴폐': 114,\n",
       " '정경두': 115,\n",
       " '에어백': 116,\n",
       " '여섯': 117,\n",
       " '명목상': 118,\n",
       " '시국': 119,\n",
       " '카나다': 120,\n",
       " '허울': 121,\n",
       " '밤잠': 122,\n",
       " '교역': 123,\n",
       " '사이클': 124,\n",
       " '미지': 125,\n",
       " '발표문': 126,\n",
       " '다국적': 127,\n",
       " '타파': 128,\n",
       " '가마솥': 129,\n",
       " '킨': 130,\n",
       " '액젓': 131,\n",
       " '미사일': 132,\n",
       " '컴즈': 133,\n",
       " '남초': 134,\n",
       " '프로그램': 135,\n",
       " '임명권자': 136,\n",
       " '경사도': 137,\n",
       " '둥': 138,\n",
       " '자기변호': 139,\n",
       " '지경': 140,\n",
       " '원비': 141,\n",
       " '망아지': 142,\n",
       " '공산물': 143,\n",
       " '매인': 144,\n",
       " '위기감': 145,\n",
       " '강원도': 146,\n",
       " '혼인': 147,\n",
       " '격문': 148,\n",
       " '동래': 149,\n",
       " '가능': 150,\n",
       " '발전사': 151,\n",
       " '파크텔': 152,\n",
       " '공직': 153,\n",
       " '지척': 154,\n",
       " '자전': 155,\n",
       " '단종': 156,\n",
       " '통화료': 157,\n",
       " '친가': 158,\n",
       " '타려': 159,\n",
       " '교차': 160,\n",
       " '서가': 161,\n",
       " '혜여': 162,\n",
       " '옛말': 163,\n",
       " '올림머리': 164,\n",
       " '망지': 165,\n",
       " '료의': 166,\n",
       " '껌': 167,\n",
       " '혈관종': 168,\n",
       " '법문': 169,\n",
       " '뇌경색': 170,\n",
       " '국고금': 171,\n",
       " '김성훈': 172,\n",
       " '화단': 173,\n",
       " '뉴우스': 174,\n",
       " '맹견': 175,\n",
       " '최신': 176,\n",
       " '이물감': 177,\n",
       " '아애': 178,\n",
       " '테라스': 179,\n",
       " '고혈압': 180,\n",
       " '센카쿠': 181,\n",
       " '추계': 182,\n",
       " '개개인': 183,\n",
       " '예진': 184,\n",
       " '동심': 185,\n",
       " '병탄': 186,\n",
       " '프로세서': 187,\n",
       " '석자': 188,\n",
       " '화등': 189,\n",
       " '주미': 190,\n",
       " '본과': 191,\n",
       " '오물': 192,\n",
       " '슈퍼주니어': 193,\n",
       " '천황봉': 194,\n",
       " '하사관': 195,\n",
       " '양도': 196,\n",
       " '구명': 197,\n",
       " '요식': 198,\n",
       " '열': 199,\n",
       " '고검': 200,\n",
       " '열쇠': 201,\n",
       " '발열': 202,\n",
       " '볼펜': 203,\n",
       " '차이나타운': 204,\n",
       " '基本': 205,\n",
       " '서요': 206,\n",
       " '광진': 207,\n",
       " '낼': 208,\n",
       " '징후': 209,\n",
       " '복사열': 210,\n",
       " '십상': 211,\n",
       " '이정호': 212,\n",
       " '유동': 213,\n",
       " '벌': 214,\n",
       " '반발': 215,\n",
       " '옹립': 216,\n",
       " '호박': 217,\n",
       " '왕위': 218,\n",
       " '러시아워': 219,\n",
       " '유무상통': 220,\n",
       " '클라우드': 221,\n",
       " '대곡역': 222,\n",
       " '근면': 223,\n",
       " '성역': 224,\n",
       " '금수': 225,\n",
       " '유기형': 226,\n",
       " '설수': 227,\n",
       " '신봉': 228,\n",
       " '맞대결': 229,\n",
       " '천대': 230,\n",
       " '파시': 231,\n",
       " '극빈자': 232,\n",
       " '더러움': 233,\n",
       " '강': 234,\n",
       " '에디슨': 235,\n",
       " '산사태': 236,\n",
       " '동내': 237,\n",
       " '族': 238,\n",
       " '톱밥': 239,\n",
       " '명목': 240,\n",
       " '퉁': 241,\n",
       " '애통': 242,\n",
       " '진술거부권': 243,\n",
       " '슬로': 244,\n",
       " '박정': 245,\n",
       " '외출': 246,\n",
       " '문직': 247,\n",
       " '귀통': 248,\n",
       " '의국': 249,\n",
       " '반열': 250,\n",
       " '자당': 251,\n",
       " '공급': 252,\n",
       " '청산가리': 253,\n",
       " '공하': 254,\n",
       " '허무': 255,\n",
       " '개포': 256,\n",
       " '농업용수': 257,\n",
       " '한산': 258,\n",
       " '국민운동': 259,\n",
       " '운전대': 260,\n",
       " '하은이': 261,\n",
       " '금메달': 262,\n",
       " '박태경': 263,\n",
       " '치': 264,\n",
       " '김영한': 265,\n",
       " '국가수반': 266,\n",
       " '이은애': 267,\n",
       " '시용': 268,\n",
       " '혁명': 269,\n",
       " '늠': 270,\n",
       " '요세미티': 271,\n",
       " '해바라기': 272,\n",
       " '전망': 273,\n",
       " '절호': 274,\n",
       " '설득력': 275,\n",
       " '반장식': 276,\n",
       " '강준': 277,\n",
       " '정형외과': 278,\n",
       " '미화원': 279,\n",
       " '탈피': 280,\n",
       " '손데': 281,\n",
       " '보호석': 282,\n",
       " '뒷개': 283,\n",
       " '임희재': 284,\n",
       " '판타지': 285,\n",
       " '저안': 286,\n",
       " '사명': 287,\n",
       " '기생충': 288,\n",
       " '헌신': 289,\n",
       " '인국': 290,\n",
       " '안소': 291,\n",
       " '전략산업': 292,\n",
       " '군포': 293,\n",
       " '도장관': 294,\n",
       " '준수': 295,\n",
       " '왕궁': 296,\n",
       " '난다': 297,\n",
       " '잿물': 298,\n",
       " '나랏돈': 299,\n",
       " '군부대': 300,\n",
       " '간신배': 301,\n",
       " '흥원': 302,\n",
       " '무사고': 303,\n",
       " '법하': 304,\n",
       " '통통배': 305,\n",
       " '성산구': 306,\n",
       " '죽여': 307,\n",
       " '유야무야': 308,\n",
       " '입각': 309,\n",
       " '물거품': 310,\n",
       " '인멸': 311,\n",
       " '검역관': 312,\n",
       " '눈총': 313,\n",
       " '구습': 314,\n",
       " '여름철': 315,\n",
       " '아들': 316,\n",
       " '착수': 317,\n",
       " '전공의': 318,\n",
       " '켄터키주': 319,\n",
       " '지휘소': 320,\n",
       " '휀': 321,\n",
       " '실낫': 322,\n",
       " '용력': 323,\n",
       " '유용': 324,\n",
       " '극감': 325,\n",
       " '고치': 326,\n",
       " '레기': 327,\n",
       " '이재직': 328,\n",
       " '이하일': 329,\n",
       " '보험자': 330,\n",
       " '깁스': 331,\n",
       " '뒷구멍': 332,\n",
       " '수임료': 333,\n",
       " '금력': 334,\n",
       " '선거철': 335,\n",
       " '아궁': 336,\n",
       " '숭정전': 337,\n",
       " '수도관': 338,\n",
       " '방아': 339,\n",
       " '교정시력': 340,\n",
       " '결실': 341,\n",
       " '잠수함': 342,\n",
       " '허기': 343,\n",
       " '실제': 344,\n",
       " '제한선': 345,\n",
       " '아고다': 346,\n",
       " '판정패': 347,\n",
       " '매출': 348,\n",
       " '전용도로': 349,\n",
       " '혜고': 350,\n",
       " '거버넌스': 351,\n",
       " '상선': 352,\n",
       " '이질': 353,\n",
       " '업성': 354,\n",
       " '방보': 355,\n",
       " '사대주의': 356,\n",
       " '부계': 357,\n",
       " '참뜻': 358,\n",
       " '루프': 359,\n",
       " '예인': 360,\n",
       " '북단': 361,\n",
       " '요정': 362,\n",
       " '연금법': 363,\n",
       " '조각': 364,\n",
       " '커트': 365,\n",
       " '글월': 366,\n",
       " '신하': 367,\n",
       " '애벌': 368,\n",
       " '공익사업': 369,\n",
       " '뚜껑': 370,\n",
       " '언': 371,\n",
       " '맛집': 372,\n",
       " '산집': 373,\n",
       " '출도': 374,\n",
       " '소비력': 375,\n",
       " '코민': 376,\n",
       " '구원': 377,\n",
       " '빅토르안': 378,\n",
       " '칫솔': 379,\n",
       " '목민심서': 380,\n",
       " '사시다': 381,\n",
       " '면담': 382,\n",
       " '폐경': 383,\n",
       " '두목': 384,\n",
       " '꾸지람': 385,\n",
       " '어폐': 386,\n",
       " '사치품': 387,\n",
       " '톡소': 388,\n",
       " '조선학': 389,\n",
       " '하감': 390,\n",
       " '생고생': 391,\n",
       " '체육부': 392,\n",
       " '이아로': 393,\n",
       " '이끼': 394,\n",
       " '규약': 395,\n",
       " '단지': 396,\n",
       " '교통수단': 397,\n",
       " '세력': 398,\n",
       " '도전자': 399,\n",
       " '닥스': 400,\n",
       " '박근': 401,\n",
       " '동한': 402,\n",
       " '푸르': 403,\n",
       " '유력자': 404,\n",
       " '모텔': 405,\n",
       " '가지각색': 406,\n",
       " '머릿수': 407,\n",
       " '위징': 408,\n",
       " '트립': 409,\n",
       " '필라': 410,\n",
       " '김모양': 411,\n",
       " '발식': 412,\n",
       " '방미': 413,\n",
       " '나가노': 414,\n",
       " '침략': 415,\n",
       " '침전물': 416,\n",
       " '강점': 417,\n",
       " '바야': 418,\n",
       " '금기': 419,\n",
       " '좌불안석': 420,\n",
       " '노다': 421,\n",
       " '여액': 422,\n",
       " '귀착': 423,\n",
       " '의자': 424,\n",
       " '승전보': 425,\n",
       " '잇': 426,\n",
       " '중성화': 427,\n",
       " '불친절': 428,\n",
       " '희극인': 429,\n",
       " '크기': 430,\n",
       " '의문': 431,\n",
       " '흙냄새': 432,\n",
       " '하기스': 433,\n",
       " '재채기': 434,\n",
       " '본적': 435,\n",
       " '큰손': 436,\n",
       " '펀드': 437,\n",
       " '권발': 438,\n",
       " '감포': 439,\n",
       " '자겁': 440,\n",
       " '모의고사': 441,\n",
       " '망설': 442,\n",
       " '숙박업': 443,\n",
       " '피탈': 444,\n",
       " '로스쿨': 445,\n",
       " '한상국': 446,\n",
       " '버스전용차로': 447,\n",
       " '경과보고': 448,\n",
       " '행각': 449,\n",
       " '김영민': 450,\n",
       " '지로': 451,\n",
       " '국면': 452,\n",
       " '추진': 453,\n",
       " '한민': 454,\n",
       " '반텐': 455,\n",
       " '수수': 456,\n",
       " '시한': 457,\n",
       " '호항': 458,\n",
       " '향기': 459,\n",
       " '후지사와': 460,\n",
       " '위로': 461,\n",
       " '도양': 462,\n",
       " '북정': 463,\n",
       " '집터': 464,\n",
       " '상우': 465,\n",
       " '수익금': 466,\n",
       " '비람': 467,\n",
       " '협의회': 468,\n",
       " '초인': 469,\n",
       " '주원인': 470,\n",
       " '군바리': 471,\n",
       " '김치': 472,\n",
       " '매수인': 473,\n",
       " '열어': 474,\n",
       " '뼘': 475,\n",
       " '불면증': 476,\n",
       " '검색어': 477,\n",
       " '기착지': 478,\n",
       " '평준': 479,\n",
       " '덩쿨': 480,\n",
       " '휘': 481,\n",
       " '하역장': 482,\n",
       " '솔잎': 483,\n",
       " '방종': 484,\n",
       " '매번': 485,\n",
       " '수억': 486,\n",
       " '스트립': 487,\n",
       " '각계': 488,\n",
       " '수생': 489,\n",
       " '이산화질소': 490,\n",
       " '원스': 491,\n",
       " '사기업': 492,\n",
       " '수혈': 493,\n",
       " '임금법': 494,\n",
       " '감각': 495,\n",
       " '음모': 496,\n",
       " '왕국': 497,\n",
       " '공과': 498,\n",
       " '선스': 499,\n",
       " '이우상': 500,\n",
       " '본말': 501,\n",
       " '세수입': 502,\n",
       " '무보험': 503,\n",
       " '크루': 504,\n",
       " '교통카드': 505,\n",
       " '화이팅': 506,\n",
       " '요령': 507,\n",
       " '주체사상': 508,\n",
       " '반쪽': 509,\n",
       " '코끼리': 510,\n",
       " '빈익빈': 511,\n",
       " '당은': 512,\n",
       " '하룻밤': 513,\n",
       " '수년전': 514,\n",
       " '소급': 515,\n",
       " '부방': 516,\n",
       " '잉여': 517,\n",
       " '차폐': 518,\n",
       " '휴전': 519,\n",
       " '유격': 520,\n",
       " '고행': 521,\n",
       " '방출': 522,\n",
       " '화무십일홍': 523,\n",
       " '자금력': 524,\n",
       " '위반자': 525,\n",
       " '석학': 526,\n",
       " '나현민': 527,\n",
       " '규모': 528,\n",
       " '치매': 529,\n",
       " '거시경제': 530,\n",
       " '롤링': 531,\n",
       " '귀향': 532,\n",
       " '창문': 533,\n",
       " '부착': 534,\n",
       " '단채': 535,\n",
       " '군신유의': 536,\n",
       " '종교애': 537,\n",
       " '인승': 538,\n",
       " '노점상': 539,\n",
       " '삼권': 540,\n",
       " '온냉방': 541,\n",
       " '이상욱': 542,\n",
       " '솔로': 543,\n",
       " '범접': 544,\n",
       " '놀라움': 545,\n",
       " '메이플': 546,\n",
       " '유압': 547,\n",
       " '몽상가': 548,\n",
       " '상세': 549,\n",
       " '김대중': 550,\n",
       " '공시가': 551,\n",
       " '어록': 552,\n",
       " '우축': 553,\n",
       " '엉망': 554,\n",
       " '리포터': 555,\n",
       " '부여': 556,\n",
       " '말린': 557,\n",
       " '솔선': 558,\n",
       " '단도직입': 559,\n",
       " '동티': 560,\n",
       " '사이크': 561,\n",
       " '스텐': 562,\n",
       " '개각': 563,\n",
       " '마다': 564,\n",
       " '터미널': 565,\n",
       " '이사장': 566,\n",
       " '인터폰': 567,\n",
       " '생멸': 568,\n",
       " '후반부': 569,\n",
       " '망국': 570,\n",
       " '급여액': 571,\n",
       " '언성': 572,\n",
       " '품목': 573,\n",
       " '가부': 574,\n",
       " '본건': 575,\n",
       " '산업은행': 576,\n",
       " '사회면': 577,\n",
       " '부지기수': 578,\n",
       " '설과': 579,\n",
       " '소취': 580,\n",
       " '와병': 581,\n",
       " '이예준': 582,\n",
       " '무고죄': 583,\n",
       " '존재감': 584,\n",
       " '결시': 585,\n",
       " '화약고': 586,\n",
       " '골판지': 587,\n",
       " '검지': 588,\n",
       " '핵보유국': 589,\n",
       " '돈줄': 590,\n",
       " '안전벨트': 591,\n",
       " '부족분': 592,\n",
       " '무인도': 593,\n",
       " '중앙일보': 594,\n",
       " '코디': 595,\n",
       " '종원': 596,\n",
       " '산지': 597,\n",
       " '기가': 598,\n",
       " '정보관': 599,\n",
       " '떼거지': 600,\n",
       " '헌가': 601,\n",
       " '소양호': 602,\n",
       " '참회': 603,\n",
       " '추장': 604,\n",
       " '여긴': 605,\n",
       " '아마추어': 606,\n",
       " '황룡동': 607,\n",
       " '정운호': 608,\n",
       " '시행법': 609,\n",
       " '아바타': 610,\n",
       " '오컴': 611,\n",
       " '불덩이': 612,\n",
       " '소평': 613,\n",
       " '친환': 614,\n",
       " '츠': 615,\n",
       " '특효약': 616,\n",
       " '상간자': 617,\n",
       " '숙박업소': 618,\n",
       " '예술가': 619,\n",
       " '교통사고': 620,\n",
       " '관점': 621,\n",
       " '맨하탄': 622,\n",
       " '내생': 623,\n",
       " '류화선': 624,\n",
       " '지방문': 625,\n",
       " '출로': 626,\n",
       " '박상기': 627,\n",
       " '오픽': 628,\n",
       " '인내심': 629,\n",
       " '켤레': 630,\n",
       " '천기누설': 631,\n",
       " '과소평가': 632,\n",
       " '척추': 633,\n",
       " '심보': 634,\n",
       " '다혈질': 635,\n",
       " '파이널': 636,\n",
       " '교활': 637,\n",
       " '포망': 638,\n",
       " '적음': 639,\n",
       " '관직': 640,\n",
       " '예민': 641,\n",
       " '날도둑': 642,\n",
       " '잡것': 643,\n",
       " '한대': 644,\n",
       " '어원': 645,\n",
       " '언행': 646,\n",
       " '토대': 647,\n",
       " '바늘귀': 648,\n",
       " '병참': 649,\n",
       " '질투심': 650,\n",
       " '주지': 651,\n",
       " '고민상': 652,\n",
       " '인용': 653,\n",
       " '탈골': 654,\n",
       " '공공시설': 655,\n",
       " '취임식': 656,\n",
       " '활약': 657,\n",
       " '임상': 658,\n",
       " '필요시': 659,\n",
       " '전함': 660,\n",
       " '월래': 661,\n",
       " '캄': 662,\n",
       " '복통': 663,\n",
       " '구경': 664,\n",
       " '병원': 665,\n",
       " '자둥': 666,\n",
       " '외인부대': 667,\n",
       " '배짱': 668,\n",
       " '개망나니': 669,\n",
       " '동관': 670,\n",
       " '퇴근': 671,\n",
       " '제보자': 672,\n",
       " '검사원': 673,\n",
       " '만화책': 674,\n",
       " '출석': 675,\n",
       " '계몽': 676,\n",
       " '고문': 677,\n",
       " '한계': 678,\n",
       " '복부': 679,\n",
       " '군정': 680,\n",
       " '지리산': 681,\n",
       " '입영': 682,\n",
       " '기우': 683,\n",
       " '사이클론': 684,\n",
       " '사격': 685,\n",
       " '주덕읍': 686,\n",
       " '성형수술': 687,\n",
       " '명고': 688,\n",
       " '절대다수': 689,\n",
       " '잡화': 690,\n",
       " '안호영': 691,\n",
       " '일쑤': 692,\n",
       " '발급': 693,\n",
       " '난장판': 694,\n",
       " '결제': 695,\n",
       " '예고': 696,\n",
       " '위지': 697,\n",
       " '최저임금': 698,\n",
       " '불럿': 699,\n",
       " '호치': 700,\n",
       " '칠절': 701,\n",
       " '비닐통': 702,\n",
       " '가공육': 703,\n",
       " '겨울철': 704,\n",
       " '고경면': 705,\n",
       " '현수': 706,\n",
       " '베타선': 707,\n",
       " '책무': 708,\n",
       " '전배': 709,\n",
       " '심심': 710,\n",
       " '신천': 711,\n",
       " '편파': 712,\n",
       " '손안': 713,\n",
       " '잔당': 714,\n",
       " '석유공사': 715,\n",
       " '돌망태': 716,\n",
       " '꽃매미': 717,\n",
       " '안구근': 718,\n",
       " '족구': 719,\n",
       " '경적': 720,\n",
       " '大統領': 721,\n",
       " '대령': 722,\n",
       " '성황': 723,\n",
       " '육로': 724,\n",
       " '의시': 725,\n",
       " '이지환': 726,\n",
       " '양정': 727,\n",
       " '김엽래': 728,\n",
       " '행운': 729,\n",
       " '국격': 730,\n",
       " '류자': 731,\n",
       " '허영심': 732,\n",
       " '초저': 733,\n",
       " '총성': 734,\n",
       " '핵미사일': 735,\n",
       " '매물': 736,\n",
       " '탑승객': 737,\n",
       " '상가': 738,\n",
       " '소세': 739,\n",
       " '건축가': 740,\n",
       " '면소': 741,\n",
       " '파묘': 742,\n",
       " '크시': 743,\n",
       " '영농': 744,\n",
       " '진공': 745,\n",
       " '아박': 746,\n",
       " '댄': 747,\n",
       " '오락장': 748,\n",
       " '중이염': 749,\n",
       " '水': 750,\n",
       " '한판': 751,\n",
       " '지급기': 752,\n",
       " '사농공상': 753,\n",
       " '수호자': 754,\n",
       " '용역': 755,\n",
       " '정총': 756,\n",
       " '관저': 757,\n",
       " '모듈': 758,\n",
       " '해군': 759,\n",
       " '모범생': 760,\n",
       " '눈코': 761,\n",
       " '성표': 762,\n",
       " '개강': 763,\n",
       " '펭귄': 764,\n",
       " '호재': 765,\n",
       " '연세': 766,\n",
       " '하이라이트': 767,\n",
       " '제국주의자': 768,\n",
       " '용': 769,\n",
       " '장식': 770,\n",
       " '준용': 771,\n",
       " '대학살': 772,\n",
       " '어자': 773,\n",
       " '팔당': 774,\n",
       " '직급': 775,\n",
       " '장체': 776,\n",
       " '추앙': 777,\n",
       " '北道': 778,\n",
       " '입장료': 779,\n",
       " '이에': 780,\n",
       " '산유': 781,\n",
       " '연형': 782,\n",
       " '순시선': 783,\n",
       " '외계': 784,\n",
       " '신한은행': 785,\n",
       " '유턴': 786,\n",
       " '是日也放聲大哭': 787,\n",
       " '곪음': 788,\n",
       " '귀': 789,\n",
       " '달샤벳': 790,\n",
       " '정정': 791,\n",
       " '신례원': 792,\n",
       " '휴': 793,\n",
       " '독학': 794,\n",
       " '外': 795,\n",
       " '대미': 796,\n",
       " '연이': 797,\n",
       " '제청': 798,\n",
       " '소아암': 799,\n",
       " '번역가': 800,\n",
       " '착화': 801,\n",
       " '생신': 802,\n",
       " '김정남': 803,\n",
       " '별책': 804,\n",
       " '식탁': 805,\n",
       " '쇠로': 806,\n",
       " '강바닥': 807,\n",
       " '음식': 808,\n",
       " '일터': 809,\n",
       " '소방대원': 810,\n",
       " '캅': 811,\n",
       " '종로구': 812,\n",
       " '환법': 813,\n",
       " '출판물': 814,\n",
       " '담배꽁초': 815,\n",
       " '희망자': 816,\n",
       " '자행': 817,\n",
       " '비용': 818,\n",
       " '기술원': 819,\n",
       " '리뉴': 820,\n",
       " '무뢰한': 821,\n",
       " '지름길': 822,\n",
       " '마무리': 823,\n",
       " '共滅': 824,\n",
       " '리도': 825,\n",
       " '극상': 826,\n",
       " '담뱃불': 827,\n",
       " '정작': 828,\n",
       " '닛산': 829,\n",
       " '과천': 830,\n",
       " '합의체': 831,\n",
       " '분립': 832,\n",
       " '장단점': 833,\n",
       " '요양원': 834,\n",
       " '시리': 835,\n",
       " '성직자': 836,\n",
       " '보중': 837,\n",
       " '정진석': 838,\n",
       " '이판사판': 839,\n",
       " '지어': 840,\n",
       " '저그': 841,\n",
       " '승패': 842,\n",
       " '유부녀': 843,\n",
       " '잎새': 844,\n",
       " '목적어': 845,\n",
       " '영정': 846,\n",
       " '륵': 847,\n",
       " '증자': 848,\n",
       " '이회창': 849,\n",
       " '석가': 850,\n",
       " '생불': 851,\n",
       " '운전병': 852,\n",
       " '자주권': 853,\n",
       " '진학': 854,\n",
       " '발파': 855,\n",
       " '독남': 856,\n",
       " '유류': 857,\n",
       " '뎅기열': 858,\n",
       " '뚱딴지': 859,\n",
       " '증평': 860,\n",
       " '홍윤식': 861,\n",
       " '차종': 862,\n",
       " '필부': 863,\n",
       " '메가': 864,\n",
       " '중소': 865,\n",
       " '불효': 866,\n",
       " '정인': 867,\n",
       " '말소': 868,\n",
       " '불명': 869,\n",
       " '남서향': 870,\n",
       " '소격동': 871,\n",
       " '자칼': 872,\n",
       " '법무': 873,\n",
       " '손익계산서': 874,\n",
       " '신동빈': 875,\n",
       " '서훈': 876,\n",
       " '호스': 877,\n",
       " '이인원': 878,\n",
       " '취임사': 879,\n",
       " '스페셜': 880,\n",
       " '건단': 881,\n",
       " '하우스': 882,\n",
       " '승전': 883,\n",
       " '아이비리그': 884,\n",
       " '체납자': 885,\n",
       " '화인봉': 886,\n",
       " '습득': 887,\n",
       " '주먹구구식': 888,\n",
       " '선린': 889,\n",
       " '자융': 890,\n",
       " '거름': 891,\n",
       " '내오': 892,\n",
       " '행중': 893,\n",
       " '미포': 894,\n",
       " '대번': 895,\n",
       " '건조물': 896,\n",
       " '관도': 897,\n",
       " '피임약': 898,\n",
       " '견적서': 899,\n",
       " '가딩': 900,\n",
       " '만끽': 901,\n",
       " '우산': 902,\n",
       " '산부인과': 903,\n",
       " '교동': 904,\n",
       " '검사관': 905,\n",
       " '호출': 906,\n",
       " '재심': 907,\n",
       " '패스트': 908,\n",
       " '스터디': 909,\n",
       " '운반': 910,\n",
       " '알지': 911,\n",
       " '세곡동': 912,\n",
       " '격감': 913,\n",
       " '갇': 914,\n",
       " '마흔': 915,\n",
       " '치기': 916,\n",
       " '지상주의': 917,\n",
       " '결속': 918,\n",
       " '국왕': 919,\n",
       " '겸용': 920,\n",
       " '모계': 921,\n",
       " '착복': 922,\n",
       " '외모': 923,\n",
       " '장원': 924,\n",
       " '로비스트': 925,\n",
       " '화웨이': 926,\n",
       " '부녀자': 927,\n",
       " '산송장': 928,\n",
       " '타이틀': 929,\n",
       " '마인츠': 930,\n",
       " '이싸': 931,\n",
       " '편집국장': 932,\n",
       " '마주': 933,\n",
       " '혁역': 934,\n",
       " '커머스': 935,\n",
       " '유불리': 936,\n",
       " '대략': 937,\n",
       " '초토화': 938,\n",
       " '군축': 939,\n",
       " '로스차일드': 940,\n",
       " '혼동': 941,\n",
       " '복걸': 942,\n",
       " '후지산': 943,\n",
       " '비례식': 944,\n",
       " '전신': 945,\n",
       " '이야기': 946,\n",
       " '박양': 947,\n",
       " '미귀': 948,\n",
       " '친위': 949,\n",
       " '말자': 950,\n",
       " '조양호': 951,\n",
       " '검소': 952,\n",
       " '가리개': 953,\n",
       " '트집': 954,\n",
       " '시인': 955,\n",
       " '인시': 956,\n",
       " '소손녕': 957,\n",
       " '제창': 958,\n",
       " '永': 959,\n",
       " '전극': 960,\n",
       " '경험칙': 961,\n",
       " '크롬웰': 962,\n",
       " '지위': 963,\n",
       " '탭': 964,\n",
       " '출조': 965,\n",
       " '흉부': 966,\n",
       " '티엠': 967,\n",
       " '창원': 968,\n",
       " '미쓰': 969,\n",
       " '위급': 970,\n",
       " '국운': 971,\n",
       " '깡다구': 972,\n",
       " '유분': 973,\n",
       " '주단': 974,\n",
       " '술안주': 975,\n",
       " '자유방임': 976,\n",
       " '위신': 977,\n",
       " '우릴': 978,\n",
       " '爲政': 979,\n",
       " '상급': 980,\n",
       " '앤': 981,\n",
       " '등부': 982,\n",
       " '희석': 983,\n",
       " '재산액': 984,\n",
       " '점서': 985,\n",
       " '빈집': 986,\n",
       " '구상': 987,\n",
       " '엠': 988,\n",
       " '어촌계': 989,\n",
       " '비상계단': 990,\n",
       " '외국': 991,\n",
       " '고생문': 992,\n",
       " '행시': 993,\n",
       " '사흘': 994,\n",
       " '달랏': 995,\n",
       " '쟤': 996,\n",
       " '굴뚝': 997,\n",
       " '주안': 998,\n",
       " '시온': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    word2index[word] = i\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'미래': 0,\n",
       " '행정': 1,\n",
       " '보건복지': 2,\n",
       " '정치개혁': 3,\n",
       " '안전/환경': 4,\n",
       " '저출산/고령화대책': 5,\n",
       " '일자리': 6,\n",
       " '농산어촌': 7,\n",
       " '외교/통일/국방': 8,\n",
       " '성장동력': 9,\n",
       " '육아/교육': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = set(categories)\n",
    "targets2index = {}\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    targets2index[target] = i\n",
    "targets2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, output_size, learning_rate):\n",
    "        with tf.variable_scope(\"main\"):\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "                \n",
    "            self.inputs = tf.placeholder(tf.float32, [None, input_size], name='inputs')\n",
    "            self.targets = tf.placeholder(tf.int32, [None], name='targets')\n",
    "            self.one_hot_targets = tf.one_hot(self.targets, output_size)\n",
    "\n",
    "            self.hidden1 = tf.layers.dense(inputs=self.inputs, units=10000, activation=tf.nn.relu, name='hidden1')\n",
    "            self.hidden2 = tf.layers.dense(inputs=self.hidden1, units=1000, activation=tf.nn.relu, name='hidden2')        \n",
    "            self.hidden3 = tf.layers.dense(inputs=self.hidden2, units=100, activation=tf.nn.relu, name='hidden3')\n",
    "            self.output = tf.layers.dense(inputs=self.hidden3, units=output_size, activation=tf.nn.softmax, name='output')        \n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.one_hot_targets, logits=self.output))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "NN = NeuralNetwork(len(word2index), len(targets2index), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "save_file = './train_1000.ckpt'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 2.398\n",
      "step: 1, loss: 2.397\n",
      "step: 2, loss: 2.392\n",
      "step: 3, loss: 2.379\n",
      "step: 4, loss: 2.366\n",
      "step: 5, loss: 2.442\n",
      "step: 6, loss: 2.349\n",
      "step: 7, loss: 2.252\n",
      "step: 8, loss: 2.401\n",
      "step: 9, loss: 2.300\n",
      "step: 10, loss: 2.453\n",
      "step: 11, loss: 2.341\n",
      "step: 12, loss: 2.219\n",
      "step: 13, loss: 2.305\n",
      "step: 14, loss: 2.506\n",
      "step: 15, loss: 2.336\n",
      "step: 16, loss: 2.378\n",
      "step: 17, loss: 2.268\n",
      "step: 18, loss: 2.204\n",
      "step: 19, loss: 2.338\n",
      "step: 20, loss: 2.211\n",
      "step: 21, loss: 2.281\n",
      "step: 22, loss: 2.173\n",
      "step: 23, loss: 2.206\n",
      "step: 24, loss: 2.136\n",
      "step: 25, loss: 2.296\n",
      "step: 26, loss: 2.257\n",
      "step: 27, loss: 2.375\n",
      "step: 28, loss: 2.303\n",
      "step: 29, loss: 2.338\n",
      "step: 30, loss: 2.340\n",
      "step: 31, loss: 2.389\n",
      "step: 32, loss: 2.137\n",
      "step: 33, loss: 2.150\n",
      "step: 34, loss: 2.288\n",
      "step: 35, loss: 2.285\n",
      "step: 36, loss: 2.369\n",
      "step: 37, loss: 2.132\n",
      "step: 38, loss: 2.234\n",
      "step: 39, loss: 2.368\n",
      "step: 40, loss: 2.208\n",
      "step: 41, loss: 2.225\n",
      "step: 42, loss: 2.379\n",
      "step: 43, loss: 2.388\n",
      "step: 44, loss: 2.287\n",
      "step: 45, loss: 2.150\n",
      "step: 46, loss: 2.304\n",
      "step: 47, loss: 2.262\n",
      "step: 48, loss: 2.290\n",
      "step: 49, loss: 2.003\n",
      "step: 50, loss: 2.208\n",
      "step: 51, loss: 2.133\n",
      "step: 52, loss: 2.225\n",
      "step: 53, loss: 2.108\n",
      "step: 54, loss: 2.245\n",
      "step: 55, loss: 2.181\n",
      "step: 56, loss: 2.226\n",
      "step: 57, loss: 2.164\n",
      "step: 58, loss: 2.002\n",
      "step: 59, loss: 2.162\n",
      "step: 60, loss: 2.302\n",
      "step: 61, loss: 1.920\n",
      "step: 62, loss: 2.228\n",
      "step: 63, loss: 2.233\n",
      "step: 64, loss: 2.139\n",
      "step: 65, loss: 2.321\n",
      "step: 66, loss: 2.223\n",
      "step: 67, loss: 2.227\n",
      "step: 68, loss: 2.265\n",
      "step: 69, loss: 2.326\n",
      "step: 70, loss: 2.052\n",
      "step: 71, loss: 2.104\n",
      "step: 72, loss: 2.067\n",
      "step: 73, loss: 2.020\n",
      "step: 74, loss: 2.254\n",
      "step: 75, loss: 2.238\n",
      "step: 76, loss: 2.138\n",
      "step: 77, loss: 2.246\n",
      "step: 78, loss: 2.229\n",
      "step: 79, loss: 2.161\n",
      "step: 80, loss: 2.061\n",
      "step: 81, loss: 2.181\n",
      "step: 82, loss: 2.277\n",
      "step: 83, loss: 1.927\n",
      "step: 84, loss: 1.971\n",
      "step: 85, loss: 2.293\n",
      "step: 86, loss: 2.219\n",
      "step: 87, loss: 2.119\n",
      "step: 88, loss: 2.274\n",
      "step: 89, loss: 2.093\n",
      "step: 90, loss: 2.086\n",
      "step: 91, loss: 2.133\n",
      "step: 92, loss: 2.159\n",
      "step: 93, loss: 2.055\n",
      "step: 94, loss: 2.024\n",
      "step: 95, loss: 1.910\n",
      "step: 96, loss: 2.075\n",
      "step: 97, loss: 2.267\n",
      "step: 98, loss: 2.242\n",
      "step: 99, loss: 1.935\n",
      "step: 100, loss: 2.098\n",
      "step: 101, loss: 1.970\n",
      "step: 102, loss: 2.034\n",
      "step: 103, loss: 2.066\n",
      "step: 104, loss: 2.158\n",
      "step: 105, loss: 2.217\n",
      "step: 106, loss: 1.976\n",
      "step: 107, loss: 2.199\n",
      "step: 108, loss: 2.100\n",
      "step: 109, loss: 2.112\n",
      "step: 110, loss: 2.067\n",
      "step: 111, loss: 2.013\n",
      "step: 112, loss: 2.141\n",
      "step: 113, loss: 1.978\n",
      "step: 114, loss: 2.115\n",
      "step: 115, loss: 2.104\n",
      "step: 116, loss: 2.120\n",
      "step: 117, loss: 2.108\n",
      "step: 118, loss: 2.073\n",
      "step: 119, loss: 2.012\n",
      "step: 120, loss: 2.210\n",
      "step: 121, loss: 1.919\n",
      "step: 122, loss: 2.037\n",
      "step: 123, loss: 2.118\n",
      "step: 124, loss: 2.035\n",
      "step: 125, loss: 2.093\n",
      "step: 126, loss: 2.060\n",
      "step: 127, loss: 1.930\n",
      "step: 128, loss: 1.966\n",
      "step: 129, loss: 2.037\n",
      "step: 130, loss: 2.059\n",
      "step: 131, loss: 1.930\n",
      "step: 132, loss: 2.126\n",
      "step: 133, loss: 2.115\n",
      "step: 134, loss: 2.190\n",
      "step: 135, loss: 2.106\n",
      "step: 136, loss: 2.018\n",
      "step: 137, loss: 1.880\n",
      "step: 138, loss: 2.132\n",
      "step: 139, loss: 2.109\n",
      "step: 140, loss: 2.341\n",
      "step: 141, loss: 1.965\n",
      "step: 142, loss: 2.142\n",
      "step: 143, loss: 2.069\n",
      "step: 144, loss: 1.990\n",
      "step: 145, loss: 1.848\n",
      "step: 146, loss: 2.046\n",
      "step: 147, loss: 2.139\n",
      "step: 148, loss: 2.062\n",
      "step: 149, loss: 2.002\n",
      "step: 150, loss: 2.023\n",
      "step: 151, loss: 2.130\n",
      "step: 152, loss: 2.140\n",
      "step: 153, loss: 2.306\n",
      "step: 154, loss: 1.875\n",
      "step: 155, loss: 1.981\n",
      "step: 156, loss: 2.171\n",
      "step: 157, loss: 1.847\n",
      "step: 158, loss: 2.017\n",
      "step: 159, loss: 2.037\n",
      "step: 160, loss: 2.034\n",
      "step: 161, loss: 2.167\n",
      "step: 162, loss: 1.845\n",
      "step: 163, loss: 2.121\n",
      "step: 164, loss: 2.049\n",
      "step: 165, loss: 1.957\n",
      "step: 166, loss: 2.395\n",
      "step: 167, loss: 2.011\n",
      "step: 168, loss: 2.162\n",
      "step: 169, loss: 2.053\n",
      "step: 170, loss: 2.094\n",
      "step: 171, loss: 2.037\n",
      "step: 172, loss: 2.116\n",
      "step: 173, loss: 2.061\n",
      "step: 174, loss: 1.982\n",
      "step: 175, loss: 1.918\n",
      "step: 176, loss: 2.048\n",
      "step: 177, loss: 2.145\n",
      "step: 178, loss: 2.081\n",
      "step: 179, loss: 1.984\n",
      "step: 180, loss: 2.229\n",
      "step: 181, loss: 2.255\n",
      "step: 182, loss: 2.104\n",
      "step: 183, loss: 1.755\n",
      "step: 184, loss: 1.986\n",
      "step: 185, loss: 2.038\n",
      "step: 186, loss: 2.028\n",
      "step: 187, loss: 1.852\n",
      "step: 188, loss: 2.134\n",
      "step: 189, loss: 1.984\n",
      "step: 190, loss: 2.163\n",
      "step: 191, loss: 2.370\n",
      "step: 192, loss: 2.113\n",
      "step: 193, loss: 2.031\n",
      "step: 194, loss: 2.264\n",
      "step: 195, loss: 2.041\n",
      "step: 196, loss: 1.982\n",
      "step: 197, loss: 2.062\n",
      "step: 198, loss: 2.047\n",
      "step: 199, loss: 2.229\n",
      "step: 200, loss: 2.121\n",
      "step: 201, loss: 2.167\n",
      "step: 202, loss: 2.026\n",
      "step: 203, loss: 2.130\n",
      "step: 204, loss: 2.043\n",
      "step: 205, loss: 2.066\n",
      "step: 206, loss: 2.094\n",
      "step: 207, loss: 2.040\n",
      "step: 208, loss: 1.927\n",
      "step: 209, loss: 2.152\n",
      "step: 210, loss: 1.752\n",
      "step: 211, loss: 2.094\n",
      "step: 212, loss: 2.106\n",
      "step: 213, loss: 2.103\n",
      "step: 214, loss: 1.921\n",
      "step: 215, loss: 1.985\n",
      "step: 216, loss: 2.293\n",
      "step: 217, loss: 1.849\n",
      "step: 218, loss: 1.913\n",
      "step: 219, loss: 2.042\n",
      "step: 220, loss: 2.095\n",
      "step: 221, loss: 2.043\n",
      "step: 222, loss: 2.173\n",
      "step: 223, loss: 1.991\n",
      "step: 224, loss: 2.005\n",
      "step: 225, loss: 1.975\n",
      "step: 226, loss: 2.035\n",
      "step: 227, loss: 2.290\n",
      "step: 228, loss: 2.106\n",
      "step: 229, loss: 1.948\n",
      "step: 230, loss: 2.026\n",
      "step: 231, loss: 2.160\n",
      "step: 232, loss: 2.147\n",
      "step: 233, loss: 2.104\n",
      "step: 234, loss: 2.167\n",
      "step: 235, loss: 2.183\n",
      "step: 236, loss: 2.051\n",
      "step: 237, loss: 2.003\n",
      "step: 238, loss: 2.095\n",
      "step: 239, loss: 2.174\n",
      "step: 240, loss: 2.042\n",
      "step: 241, loss: 1.972\n",
      "step: 242, loss: 2.073\n",
      "step: 243, loss: 2.000\n",
      "step: 244, loss: 2.148\n",
      "step: 245, loss: 2.044\n",
      "step: 246, loss: 2.060\n",
      "step: 247, loss: 2.099\n",
      "step: 248, loss: 2.039\n",
      "step: 249, loss: 2.093\n",
      "step: 250, loss: 2.002\n",
      "step: 251, loss: 2.107\n",
      "step: 252, loss: 2.051\n",
      "step: 253, loss: 2.042\n",
      "step: 254, loss: 1.856\n",
      "step: 255, loss: 2.222\n",
      "step: 256, loss: 1.846\n",
      "step: 257, loss: 2.104\n",
      "step: 258, loss: 2.031\n",
      "step: 259, loss: 2.042\n",
      "step: 260, loss: 2.092\n",
      "step: 261, loss: 1.996\n",
      "step: 262, loss: 1.932\n",
      "step: 263, loss: 2.104\n",
      "step: 264, loss: 2.041\n",
      "step: 265, loss: 1.985\n",
      "step: 266, loss: 2.075\n",
      "step: 267, loss: 1.857\n",
      "step: 268, loss: 2.040\n",
      "step: 269, loss: 2.104\n",
      "step: 270, loss: 2.000\n",
      "step: 271, loss: 1.976\n",
      "step: 272, loss: 2.161\n",
      "step: 273, loss: 1.996\n",
      "step: 274, loss: 1.868\n",
      "step: 275, loss: 2.096\n",
      "step: 276, loss: 2.099\n",
      "step: 277, loss: 1.978\n",
      "step: 278, loss: 2.191\n",
      "step: 279, loss: 2.091\n",
      "step: 280, loss: 2.092\n",
      "step: 281, loss: 2.134\n",
      "step: 282, loss: 2.168\n",
      "step: 283, loss: 1.969\n",
      "step: 284, loss: 2.006\n",
      "step: 285, loss: 1.918\n",
      "step: 286, loss: 2.032\n",
      "step: 287, loss: 2.263\n",
      "step: 288, loss: 2.043\n",
      "step: 289, loss: 2.020\n",
      "step: 290, loss: 1.873\n",
      "step: 291, loss: 2.049\n",
      "step: 292, loss: 2.112\n",
      "step: 293, loss: 2.163\n",
      "step: 294, loss: 2.290\n",
      "step: 295, loss: 2.116\n",
      "step: 296, loss: 2.162\n",
      "step: 297, loss: 2.053\n",
      "step: 298, loss: 2.088\n",
      "step: 299, loss: 2.111\n",
      "step: 300, loss: 1.848\n",
      "step: 301, loss: 2.021\n",
      "step: 302, loss: 2.219\n",
      "step: 303, loss: 1.995\n",
      "step: 304, loss: 2.155\n",
      "step: 305, loss: 2.040\n",
      "step: 306, loss: 2.093\n",
      "step: 307, loss: 2.340\n",
      "step: 308, loss: 2.104\n",
      "step: 309, loss: 2.041\n",
      "step: 310, loss: 2.044\n",
      "step: 311, loss: 2.120\n",
      "step: 312, loss: 2.278\n",
      "step: 313, loss: 2.144\n",
      "step: 314, loss: 2.165\n",
      "step: 315, loss: 2.050\n",
      "step: 316, loss: 2.078\n",
      "step: 317, loss: 2.041\n",
      "step: 318, loss: 2.105\n",
      "step: 319, loss: 2.041\n",
      "step: 320, loss: 2.041\n",
      "step: 321, loss: 2.054\n",
      "step: 322, loss: 2.075\n",
      "step: 323, loss: 2.013\n",
      "step: 324, loss: 2.162\n",
      "step: 325, loss: 2.019\n",
      "step: 326, loss: 2.168\n",
      "step: 327, loss: 1.942\n",
      "step: 328, loss: 2.226\n",
      "step: 329, loss: 1.971\n",
      "step: 330, loss: 2.025\n",
      "step: 331, loss: 1.955\n",
      "step: 332, loss: 2.203\n",
      "step: 333, loss: 2.103\n",
      "step: 334, loss: 2.073\n",
      "step: 335, loss: 2.005\n",
      "step: 336, loss: 1.840\n",
      "step: 337, loss: 1.978\n",
      "step: 338, loss: 1.874\n",
      "step: 339, loss: 2.076\n",
      "step: 340, loss: 1.856\n",
      "step: 341, loss: 2.103\n",
      "step: 342, loss: 2.159\n",
      "step: 343, loss: 2.034\n",
      "step: 344, loss: 2.217\n",
      "step: 345, loss: 2.195\n",
      "step: 346, loss: 2.165\n",
      "step: 347, loss: 2.041\n",
      "step: 348, loss: 1.976\n",
      "step: 349, loss: 2.101\n",
      "step: 350, loss: 2.291\n",
      "step: 351, loss: 1.988\n",
      "step: 352, loss: 2.160\n",
      "step: 353, loss: 2.166\n",
      "step: 354, loss: 2.132\n",
      "step: 355, loss: 2.147\n",
      "step: 356, loss: 2.035\n",
      "step: 357, loss: 1.913\n",
      "step: 358, loss: 2.229\n",
      "step: 359, loss: 2.158\n",
      "step: 360, loss: 1.899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 361, loss: 2.109\n",
      "step: 362, loss: 2.100\n",
      "step: 363, loss: 2.144\n",
      "step: 364, loss: 2.086\n",
      "step: 365, loss: 2.024\n",
      "step: 366, loss: 2.166\n",
      "step: 367, loss: 2.035\n",
      "step: 368, loss: 2.113\n",
      "step: 369, loss: 2.102\n",
      "step: 370, loss: 2.167\n",
      "step: 371, loss: 2.224\n",
      "step: 372, loss: 2.291\n",
      "step: 373, loss: 2.063\n",
      "step: 374, loss: 1.856\n",
      "step: 375, loss: 1.977\n",
      "step: 376, loss: 2.227\n",
      "step: 377, loss: 2.166\n",
      "step: 378, loss: 2.285\n",
      "step: 379, loss: 2.000\n",
      "step: 380, loss: 2.088\n",
      "step: 381, loss: 1.950\n",
      "step: 382, loss: 2.223\n",
      "step: 383, loss: 1.667\n",
      "step: 384, loss: 1.997\n",
      "step: 385, loss: 2.043\n",
      "step: 386, loss: 1.912\n",
      "step: 387, loss: 1.741\n",
      "step: 388, loss: 1.917\n",
      "step: 389, loss: 1.964\n",
      "step: 390, loss: 2.043\n",
      "step: 391, loss: 2.137\n",
      "step: 392, loss: 2.070\n",
      "step: 393, loss: 2.041\n",
      "step: 394, loss: 1.973\n",
      "step: 395, loss: 2.043\n",
      "step: 396, loss: 1.978\n",
      "step: 397, loss: 2.059\n",
      "step: 398, loss: 1.972\n",
      "step: 399, loss: 2.104\n",
      "step: 400, loss: 1.946\n",
      "step: 401, loss: 1.980\n",
      "step: 402, loss: 1.953\n",
      "step: 403, loss: 1.975\n",
      "step: 404, loss: 2.178\n",
      "step: 405, loss: 2.092\n",
      "step: 406, loss: 1.981\n",
      "step: 407, loss: 2.042\n",
      "step: 408, loss: 1.918\n",
      "step: 409, loss: 2.074\n",
      "step: 410, loss: 1.942\n",
      "step: 411, loss: 1.978\n",
      "step: 412, loss: 1.856\n",
      "step: 413, loss: 2.167\n",
      "step: 414, loss: 2.103\n",
      "step: 415, loss: 2.229\n",
      "step: 416, loss: 1.978\n",
      "step: 417, loss: 2.104\n",
      "step: 418, loss: 2.129\n",
      "step: 419, loss: 1.919\n",
      "step: 420, loss: 1.979\n",
      "step: 421, loss: 2.021\n",
      "step: 422, loss: 1.941\n",
      "step: 423, loss: 2.290\n",
      "step: 424, loss: 1.980\n",
      "step: 425, loss: 2.173\n",
      "step: 426, loss: 2.042\n",
      "step: 427, loss: 2.292\n",
      "step: 428, loss: 1.964\n",
      "step: 429, loss: 1.916\n",
      "step: 430, loss: 2.011\n",
      "step: 431, loss: 2.043\n",
      "step: 432, loss: 2.081\n",
      "step: 433, loss: 2.253\n",
      "step: 434, loss: 2.101\n",
      "step: 435, loss: 1.977\n",
      "step: 436, loss: 1.978\n",
      "step: 437, loss: 2.042\n",
      "step: 438, loss: 2.044\n",
      "step: 439, loss: 2.162\n",
      "step: 440, loss: 2.168\n",
      "step: 441, loss: 2.040\n",
      "step: 442, loss: 1.929\n",
      "step: 443, loss: 2.036\n",
      "step: 444, loss: 2.125\n",
      "step: 445, loss: 2.174\n",
      "step: 446, loss: 2.340\n",
      "step: 447, loss: 1.855\n",
      "step: 448, loss: 2.175\n",
      "step: 449, loss: 2.118\n",
      "step: 450, loss: 1.958\n",
      "step: 451, loss: 2.043\n",
      "step: 452, loss: 1.973\n",
      "step: 453, loss: 2.042\n",
      "step: 454, loss: 1.979\n",
      "step: 455, loss: 2.039\n",
      "step: 456, loss: 1.918\n",
      "step: 457, loss: 1.793\n",
      "step: 458, loss: 2.088\n",
      "step: 459, loss: 2.096\n",
      "step: 460, loss: 1.887\n",
      "step: 461, loss: 2.011\n",
      "step: 462, loss: 2.107\n",
      "step: 463, loss: 1.917\n",
      "step: 464, loss: 2.045\n",
      "step: 465, loss: 2.292\n",
      "step: 466, loss: 2.090\n",
      "step: 467, loss: 2.179\n",
      "step: 468, loss: 1.905\n",
      "step: 469, loss: 1.846\n",
      "step: 470, loss: 2.106\n",
      "step: 471, loss: 2.233\n",
      "step: 472, loss: 2.228\n",
      "step: 473, loss: 2.009\n",
      "step: 474, loss: 2.148\n",
      "step: 475, loss: 1.985\n",
      "step: 476, loss: 1.976\n",
      "step: 477, loss: 2.105\n",
      "step: 478, loss: 1.971\n",
      "step: 479, loss: 2.052\n",
      "step: 480, loss: 2.166\n",
      "step: 481, loss: 2.042\n",
      "step: 482, loss: 2.040\n",
      "step: 483, loss: 1.918\n",
      "step: 484, loss: 1.917\n",
      "step: 485, loss: 2.107\n",
      "step: 486, loss: 2.060\n",
      "step: 487, loss: 2.064\n",
      "step: 488, loss: 2.104\n",
      "step: 489, loss: 2.109\n",
      "step: 490, loss: 1.937\n",
      "step: 491, loss: 1.981\n",
      "step: 492, loss: 2.168\n",
      "step: 493, loss: 1.983\n",
      "step: 494, loss: 2.105\n",
      "step: 495, loss: 1.981\n",
      "step: 496, loss: 2.086\n",
      "step: 497, loss: 1.855\n",
      "step: 498, loss: 2.039\n",
      "step: 499, loss: 2.052\n",
      "step: 500, loss: 2.093\n",
      "step: 501, loss: 2.352\n",
      "step: 502, loss: 2.286\n",
      "step: 503, loss: 2.031\n",
      "step: 504, loss: 1.929\n",
      "step: 505, loss: 2.167\n",
      "step: 506, loss: 2.049\n",
      "step: 507, loss: 2.110\n",
      "step: 508, loss: 1.855\n",
      "step: 509, loss: 2.040\n",
      "step: 510, loss: 2.228\n",
      "step: 511, loss: 2.354\n",
      "step: 512, loss: 2.187\n",
      "step: 513, loss: 2.205\n",
      "step: 514, loss: 2.166\n",
      "step: 515, loss: 2.261\n",
      "step: 516, loss: 1.960\n",
      "step: 517, loss: 2.145\n",
      "step: 518, loss: 2.103\n",
      "step: 519, loss: 2.043\n",
      "step: 520, loss: 1.986\n",
      "step: 521, loss: 1.993\n",
      "step: 522, loss: 2.168\n",
      "step: 523, loss: 1.978\n",
      "step: 524, loss: 2.227\n",
      "step: 525, loss: 2.226\n",
      "step: 526, loss: 2.063\n",
      "step: 527, loss: 2.162\n",
      "step: 528, loss: 1.982\n",
      "step: 529, loss: 1.853\n",
      "step: 530, loss: 1.909\n",
      "step: 531, loss: 2.025\n",
      "step: 532, loss: 1.918\n",
      "step: 533, loss: 2.106\n",
      "step: 534, loss: 2.105\n",
      "step: 535, loss: 2.041\n",
      "step: 536, loss: 2.042\n",
      "step: 537, loss: 1.903\n",
      "step: 538, loss: 1.975\n",
      "step: 539, loss: 1.855\n",
      "step: 540, loss: 2.105\n",
      "step: 541, loss: 2.043\n",
      "step: 542, loss: 2.018\n",
      "step: 543, loss: 2.045\n",
      "step: 544, loss: 2.038\n",
      "step: 545, loss: 2.043\n",
      "step: 546, loss: 1.918\n",
      "step: 547, loss: 2.043\n",
      "step: 548, loss: 2.084\n",
      "step: 549, loss: 2.104\n",
      "step: 550, loss: 2.164\n",
      "step: 551, loss: 2.038\n",
      "step: 552, loss: 1.980\n",
      "step: 553, loss: 2.230\n",
      "step: 554, loss: 1.981\n",
      "step: 555, loss: 2.042\n",
      "step: 556, loss: 2.043\n",
      "step: 557, loss: 2.106\n",
      "step: 558, loss: 1.856\n",
      "step: 559, loss: 2.052\n",
      "step: 560, loss: 1.918\n",
      "step: 561, loss: 2.168\n",
      "step: 562, loss: 2.104\n",
      "step: 563, loss: 1.980\n",
      "step: 564, loss: 1.966\n",
      "step: 565, loss: 1.917\n",
      "step: 566, loss: 1.855\n",
      "step: 567, loss: 2.171\n",
      "step: 568, loss: 2.043\n",
      "step: 569, loss: 1.993\n",
      "step: 570, loss: 2.043\n",
      "step: 571, loss: 1.854\n",
      "step: 572, loss: 2.236\n",
      "step: 573, loss: 1.817\n",
      "step: 574, loss: 2.037\n",
      "step: 575, loss: 2.042\n",
      "step: 576, loss: 1.969\n",
      "step: 577, loss: 2.043\n",
      "step: 578, loss: 2.001\n",
      "step: 579, loss: 2.153\n",
      "step: 580, loss: 1.731\n",
      "step: 581, loss: 1.981\n",
      "step: 582, loss: 2.103\n",
      "step: 583, loss: 1.980\n",
      "step: 584, loss: 2.106\n",
      "step: 585, loss: 2.121\n",
      "step: 586, loss: 1.981\n",
      "step: 587, loss: 2.259\n",
      "step: 588, loss: 1.928\n",
      "step: 589, loss: 1.918\n",
      "step: 590, loss: 2.226\n",
      "step: 591, loss: 1.979\n",
      "step: 592, loss: 2.165\n",
      "step: 593, loss: 2.042\n",
      "step: 594, loss: 2.287\n",
      "step: 595, loss: 2.104\n",
      "step: 596, loss: 2.277\n",
      "step: 597, loss: 2.070\n",
      "step: 598, loss: 2.103\n",
      "step: 599, loss: 2.230\n",
      "step: 600, loss: 2.065\n",
      "step: 601, loss: 1.793\n",
      "step: 602, loss: 2.355\n",
      "step: 603, loss: 2.124\n",
      "step: 604, loss: 2.194\n",
      "step: 605, loss: 2.297\n",
      "step: 606, loss: 1.980\n",
      "step: 607, loss: 2.106\n",
      "step: 608, loss: 2.080\n",
      "step: 609, loss: 1.981\n",
      "step: 610, loss: 2.086\n",
      "step: 611, loss: 2.043\n",
      "step: 612, loss: 2.168\n",
      "step: 613, loss: 1.980\n",
      "step: 614, loss: 2.041\n",
      "step: 615, loss: 1.981\n",
      "step: 616, loss: 2.293\n",
      "step: 617, loss: 1.790\n",
      "step: 618, loss: 2.155\n",
      "step: 619, loss: 2.041\n",
      "step: 620, loss: 1.987\n",
      "step: 621, loss: 2.228\n",
      "step: 622, loss: 2.127\n",
      "step: 623, loss: 2.097\n",
      "step: 624, loss: 2.106\n",
      "step: 625, loss: 2.172\n",
      "step: 626, loss: 1.979\n",
      "step: 627, loss: 1.918\n",
      "step: 628, loss: 1.840\n",
      "step: 629, loss: 1.981\n",
      "step: 630, loss: 2.061\n",
      "step: 631, loss: 2.116\n",
      "step: 632, loss: 1.977\n",
      "step: 633, loss: 1.981\n",
      "step: 634, loss: 2.280\n",
      "step: 635, loss: 1.917\n",
      "step: 636, loss: 2.165\n",
      "step: 637, loss: 2.052\n",
      "step: 638, loss: 1.918\n",
      "step: 639, loss: 2.045\n",
      "step: 640, loss: 1.976\n",
      "step: 641, loss: 2.168\n",
      "step: 642, loss: 1.917\n",
      "step: 643, loss: 2.050\n",
      "step: 644, loss: 2.156\n",
      "step: 645, loss: 1.849\n",
      "step: 646, loss: 1.787\n",
      "step: 647, loss: 1.858\n",
      "step: 648, loss: 1.975\n",
      "step: 649, loss: 2.095\n",
      "step: 650, loss: 1.918\n",
      "step: 651, loss: 2.044\n",
      "step: 652, loss: 1.829\n",
      "step: 653, loss: 1.793\n",
      "step: 654, loss: 2.046\n",
      "step: 655, loss: 2.015\n",
      "step: 656, loss: 2.226\n",
      "step: 657, loss: 1.793\n",
      "step: 658, loss: 2.110\n",
      "step: 659, loss: 1.980\n",
      "step: 660, loss: 1.918\n",
      "step: 661, loss: 1.943\n",
      "step: 662, loss: 1.933\n",
      "step: 663, loss: 2.106\n",
      "step: 664, loss: 2.205\n",
      "step: 665, loss: 2.041\n",
      "step: 666, loss: 2.043\n",
      "step: 667, loss: 2.165\n",
      "step: 668, loss: 2.104\n",
      "step: 669, loss: 2.231\n",
      "step: 670, loss: 1.794\n",
      "step: 671, loss: 2.230\n",
      "step: 672, loss: 2.098\n",
      "step: 673, loss: 1.791\n",
      "step: 674, loss: 2.168\n",
      "step: 675, loss: 2.043\n",
      "step: 676, loss: 1.816\n",
      "step: 677, loss: 1.991\n",
      "step: 678, loss: 1.918\n",
      "step: 679, loss: 2.043\n",
      "step: 680, loss: 1.920\n",
      "step: 681, loss: 2.015\n",
      "step: 682, loss: 2.038\n",
      "step: 683, loss: 2.042\n",
      "step: 684, loss: 1.959\n",
      "step: 685, loss: 2.040\n",
      "step: 686, loss: 2.099\n",
      "step: 687, loss: 2.043\n",
      "step: 688, loss: 2.162\n",
      "step: 689, loss: 2.103\n",
      "step: 690, loss: 2.043\n",
      "step: 691, loss: 2.103\n",
      "step: 692, loss: 2.167\n",
      "step: 693, loss: 2.049\n",
      "step: 694, loss: 2.102\n",
      "step: 695, loss: 2.049\n",
      "step: 696, loss: 2.041\n",
      "step: 697, loss: 2.167\n",
      "step: 698, loss: 1.981\n",
      "step: 699, loss: 1.856\n",
      "step: 700, loss: 2.114\n",
      "step: 701, loss: 2.043\n",
      "step: 702, loss: 1.987\n",
      "step: 703, loss: 1.793\n",
      "step: 704, loss: 1.918\n",
      "step: 705, loss: 1.856\n",
      "step: 706, loss: 1.793\n",
      "step: 707, loss: 1.793\n",
      "step: 708, loss: 1.870\n",
      "step: 709, loss: 2.104\n",
      "step: 710, loss: 2.169\n",
      "step: 711, loss: 1.924\n",
      "step: 712, loss: 2.068\n",
      "step: 713, loss: 1.935\n",
      "step: 714, loss: 2.105\n",
      "step: 715, loss: 1.981\n",
      "step: 716, loss: 1.918\n",
      "step: 717, loss: 2.051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 718, loss: 2.040\n",
      "step: 719, loss: 1.980\n",
      "step: 720, loss: 2.035\n",
      "step: 721, loss: 2.038\n",
      "step: 722, loss: 2.041\n",
      "step: 723, loss: 2.166\n",
      "step: 724, loss: 1.918\n",
      "step: 725, loss: 2.041\n",
      "step: 726, loss: 2.037\n",
      "step: 727, loss: 1.856\n",
      "step: 728, loss: 1.981\n",
      "step: 729, loss: 1.979\n",
      "step: 730, loss: 2.157\n",
      "step: 731, loss: 1.933\n",
      "step: 732, loss: 2.056\n",
      "step: 733, loss: 2.045\n",
      "step: 734, loss: 2.110\n",
      "step: 735, loss: 1.872\n",
      "step: 736, loss: 1.731\n",
      "step: 737, loss: 1.918\n",
      "step: 738, loss: 1.855\n",
      "step: 739, loss: 2.105\n",
      "step: 740, loss: 1.824\n",
      "step: 741, loss: 2.233\n",
      "step: 742, loss: 1.856\n",
      "step: 743, loss: 1.972\n",
      "step: 744, loss: 2.102\n",
      "step: 745, loss: 2.042\n",
      "step: 746, loss: 2.042\n",
      "step: 747, loss: 2.103\n",
      "step: 748, loss: 1.984\n",
      "step: 749, loss: 1.981\n",
      "step: 750, loss: 1.938\n",
      "step: 751, loss: 2.227\n",
      "step: 752, loss: 2.355\n",
      "step: 753, loss: 2.030\n",
      "step: 754, loss: 1.980\n",
      "step: 755, loss: 2.042\n",
      "step: 756, loss: 1.856\n",
      "step: 757, loss: 2.047\n",
      "step: 758, loss: 2.126\n",
      "step: 759, loss: 1.981\n",
      "step: 760, loss: 2.168\n",
      "step: 761, loss: 2.231\n",
      "step: 762, loss: 2.293\n",
      "step: 763, loss: 1.981\n",
      "step: 764, loss: 2.333\n",
      "step: 765, loss: 1.918\n",
      "step: 766, loss: 2.104\n",
      "step: 767, loss: 1.980\n",
      "step: 768, loss: 2.075\n",
      "step: 769, loss: 1.857\n",
      "step: 770, loss: 2.029\n",
      "step: 771, loss: 2.097\n",
      "step: 772, loss: 1.933\n",
      "step: 773, loss: 2.227\n",
      "step: 774, loss: 1.981\n",
      "step: 775, loss: 2.291\n",
      "step: 776, loss: 2.035\n",
      "step: 777, loss: 2.106\n",
      "step: 778, loss: 2.043\n",
      "step: 779, loss: 2.168\n",
      "step: 780, loss: 2.168\n",
      "step: 781, loss: 1.931\n",
      "step: 782, loss: 1.794\n",
      "step: 783, loss: 2.231\n",
      "step: 784, loss: 2.231\n",
      "step: 785, loss: 2.230\n",
      "step: 786, loss: 2.148\n",
      "step: 787, loss: 2.168\n",
      "step: 788, loss: 1.918\n",
      "step: 789, loss: 2.106\n",
      "step: 790, loss: 2.100\n",
      "step: 791, loss: 2.043\n",
      "step: 792, loss: 2.041\n",
      "step: 793, loss: 1.918\n",
      "step: 794, loss: 2.106\n",
      "step: 795, loss: 1.982\n",
      "step: 796, loss: 1.935\n",
      "step: 797, loss: 1.981\n",
      "step: 798, loss: 2.121\n",
      "step: 799, loss: 1.981\n",
      "step: 800, loss: 2.043\n",
      "step: 801, loss: 2.104\n",
      "step: 802, loss: 1.989\n",
      "step: 803, loss: 1.981\n",
      "step: 804, loss: 1.981\n",
      "step: 805, loss: 2.042\n",
      "step: 806, loss: 2.168\n",
      "step: 807, loss: 2.136\n",
      "step: 808, loss: 2.105\n",
      "step: 809, loss: 1.979\n",
      "step: 810, loss: 2.105\n",
      "step: 811, loss: 1.981\n",
      "step: 812, loss: 1.948\n",
      "step: 813, loss: 2.168\n",
      "step: 814, loss: 2.096\n",
      "step: 815, loss: 2.106\n",
      "step: 816, loss: 2.043\n",
      "step: 817, loss: 2.168\n",
      "step: 818, loss: 2.043\n",
      "step: 819, loss: 1.995\n",
      "step: 820, loss: 2.290\n",
      "step: 821, loss: 1.917\n",
      "step: 822, loss: 1.981\n",
      "step: 823, loss: 1.982\n",
      "step: 824, loss: 2.230\n",
      "step: 825, loss: 2.289\n",
      "step: 826, loss: 2.217\n",
      "step: 827, loss: 2.170\n",
      "step: 828, loss: 2.293\n",
      "step: 829, loss: 1.918\n",
      "step: 830, loss: 2.043\n",
      "step: 831, loss: 2.165\n",
      "step: 832, loss: 2.168\n",
      "step: 833, loss: 1.978\n",
      "step: 834, loss: 2.168\n",
      "step: 835, loss: 2.224\n",
      "step: 836, loss: 1.915\n",
      "step: 837, loss: 2.167\n",
      "step: 838, loss: 2.044\n",
      "step: 839, loss: 1.978\n",
      "step: 840, loss: 2.043\n",
      "step: 841, loss: 1.901\n",
      "step: 842, loss: 2.231\n",
      "step: 843, loss: 1.917\n",
      "step: 844, loss: 1.980\n",
      "step: 845, loss: 2.168\n",
      "step: 846, loss: 1.727\n",
      "step: 847, loss: 2.105\n",
      "step: 848, loss: 2.035\n",
      "step: 849, loss: 2.292\n",
      "step: 850, loss: 2.104\n",
      "step: 851, loss: 2.101\n",
      "step: 852, loss: 1.917\n",
      "step: 853, loss: 2.208\n",
      "step: 854, loss: 1.980\n",
      "step: 855, loss: 1.981\n",
      "step: 856, loss: 2.043\n",
      "step: 857, loss: 1.875\n",
      "step: 858, loss: 2.038\n",
      "step: 859, loss: 2.224\n",
      "step: 860, loss: 2.159\n",
      "step: 861, loss: 1.980\n",
      "step: 862, loss: 2.168\n",
      "step: 863, loss: 1.916\n",
      "step: 864, loss: 1.990\n",
      "step: 865, loss: 1.979\n",
      "step: 866, loss: 2.100\n",
      "step: 867, loss: 2.230\n",
      "step: 868, loss: 1.981\n",
      "step: 869, loss: 2.166\n",
      "step: 870, loss: 2.167\n",
      "step: 871, loss: 1.977\n",
      "step: 872, loss: 2.043\n",
      "step: 873, loss: 1.980\n",
      "step: 874, loss: 2.104\n",
      "step: 875, loss: 2.093\n",
      "step: 876, loss: 1.917\n",
      "step: 877, loss: 2.043\n",
      "step: 878, loss: 2.043\n",
      "step: 879, loss: 2.104\n",
      "step: 880, loss: 1.980\n",
      "step: 881, loss: 2.042\n",
      "step: 882, loss: 1.932\n",
      "step: 883, loss: 1.980\n",
      "step: 884, loss: 2.165\n",
      "step: 885, loss: 2.229\n",
      "step: 886, loss: 1.918\n",
      "step: 887, loss: 2.171\n",
      "step: 888, loss: 2.046\n",
      "step: 889, loss: 2.028\n",
      "step: 890, loss: 1.855\n",
      "step: 891, loss: 2.106\n",
      "step: 892, loss: 2.103\n",
      "step: 893, loss: 1.981\n",
      "step: 894, loss: 1.918\n",
      "step: 895, loss: 1.831\n",
      "step: 896, loss: 1.980\n",
      "step: 897, loss: 2.105\n",
      "step: 898, loss: 2.113\n",
      "step: 899, loss: 2.043\n",
      "step: 900, loss: 1.981\n",
      "step: 901, loss: 1.981\n",
      "step: 902, loss: 2.040\n",
      "step: 903, loss: 1.873\n",
      "step: 904, loss: 2.249\n",
      "step: 905, loss: 2.166\n",
      "step: 906, loss: 2.104\n",
      "step: 907, loss: 1.980\n",
      "step: 908, loss: 2.167\n",
      "step: 909, loss: 1.981\n",
      "step: 910, loss: 2.043\n",
      "step: 911, loss: 2.043\n",
      "step: 912, loss: 1.980\n",
      "step: 913, loss: 2.267\n",
      "step: 914, loss: 2.199\n",
      "step: 915, loss: 1.918\n",
      "step: 916, loss: 2.105\n",
      "step: 917, loss: 2.166\n",
      "step: 918, loss: 2.044\n",
      "step: 919, loss: 2.228\n",
      "step: 920, loss: 2.043\n",
      "step: 921, loss: 1.856\n",
      "step: 922, loss: 2.043\n",
      "step: 923, loss: 2.042\n",
      "step: 924, loss: 2.043\n",
      "step: 925, loss: 2.170\n",
      "step: 926, loss: 1.860\n",
      "step: 927, loss: 1.953\n",
      "step: 928, loss: 1.820\n",
      "step: 929, loss: 2.042\n",
      "step: 930, loss: 2.168\n",
      "step: 931, loss: 1.856\n",
      "step: 932, loss: 2.167\n",
      "step: 933, loss: 2.043\n",
      "step: 934, loss: 2.089\n",
      "step: 935, loss: 2.053\n",
      "step: 936, loss: 1.981\n",
      "step: 937, loss: 2.061\n",
      "step: 938, loss: 2.054\n",
      "step: 939, loss: 2.041\n",
      "step: 940, loss: 2.167\n",
      "step: 941, loss: 1.857\n",
      "step: 942, loss: 2.040\n",
      "step: 943, loss: 2.041\n",
      "step: 944, loss: 2.174\n",
      "step: 945, loss: 1.918\n",
      "step: 946, loss: 2.106\n",
      "step: 947, loss: 2.065\n",
      "step: 948, loss: 2.043\n",
      "step: 949, loss: 2.106\n",
      "step: 950, loss: 1.981\n",
      "step: 951, loss: 1.973\n",
      "step: 952, loss: 1.793\n",
      "step: 953, loss: 1.861\n",
      "step: 954, loss: 2.106\n",
      "step: 955, loss: 2.167\n",
      "step: 956, loss: 2.209\n",
      "step: 957, loss: 2.104\n",
      "step: 958, loss: 1.892\n",
      "step: 959, loss: 1.729\n",
      "step: 960, loss: 2.041\n",
      "step: 961, loss: 2.105\n",
      "step: 962, loss: 2.075\n",
      "step: 963, loss: 1.981\n",
      "step: 964, loss: 1.981\n",
      "step: 965, loss: 2.042\n",
      "step: 966, loss: 1.917\n",
      "step: 967, loss: 2.042\n",
      "step: 968, loss: 1.918\n",
      "step: 969, loss: 1.856\n",
      "step: 970, loss: 2.106\n",
      "step: 971, loss: 1.999\n",
      "step: 972, loss: 1.981\n",
      "step: 973, loss: 1.918\n",
      "step: 974, loss: 1.793\n",
      "step: 975, loss: 2.043\n",
      "step: 976, loss: 1.917\n",
      "step: 977, loss: 1.981\n",
      "step: 978, loss: 2.167\n",
      "step: 979, loss: 1.981\n",
      "step: 980, loss: 1.855\n",
      "step: 981, loss: 2.166\n",
      "step: 982, loss: 1.918\n",
      "step: 983, loss: 1.980\n",
      "step: 984, loss: 1.983\n",
      "step: 985, loss: 2.043\n",
      "step: 986, loss: 1.727\n",
      "step: 987, loss: 2.043\n",
      "step: 988, loss: 2.042\n",
      "step: 989, loss: 1.793\n",
      "step: 990, loss: 1.838\n",
      "step: 991, loss: 1.981\n",
      "step: 992, loss: 2.102\n",
      "step: 993, loss: 2.043\n",
      "step: 994, loss: 2.106\n",
      "step: 995, loss: 2.160\n",
      "step: 996, loss: 2.106\n",
      "step: 997, loss: 2.168\n",
      "step: 998, loss: 2.293\n",
      "step: 999, loss: 1.932\n",
      "Model saved in path: ./train_1000.ckpt\n"
     ]
    }
   ],
   "source": [
    "mini_batch = 16\n",
    "training_episodes = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for step in range(training_episodes):\n",
    "        idx = np.random.randint(len(numbers)-100, size=mini_batch)\n",
    "        \n",
    "        #word to one_hot_encoding\n",
    "        inputs = np.zeros((mini_batch, len(word2index)))\n",
    "        for i in range(mini_batch):\n",
    "            for word in contents[idx[i]]:\n",
    "                inputs[i][word2index[word]] = 1.0\n",
    "\n",
    "        #label to one_hot_encoding\n",
    "        index = []\n",
    "        for i in range(mini_batch):\n",
    "            index.append(targets2index[categories[idx[i]]])\n",
    "        index = np.array(index)\n",
    "        \n",
    "        loss, opt, one_hot, output = sess.run([NN.loss, NN.opt, NN.one_hot_targets, NN.output], feed_dict={NN.inputs: inputs.reshape(-1, len(word2index)), NN.targets: index})\n",
    "        print('step: {}, loss: {:0.3f}'.format(step, loss))\n",
    "\n",
    "    save_path = saver.save(sess, save_file)\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_1000.ckpt\n",
      "Validation\n",
      "logits: 보건복지, label: 행정\n",
      "logits: 육아/교육, label: 성장동력\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 정치개혁, label: 안전/환경\n",
      "logits: 정치개혁, label: 외교/통일/국방\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 외교/통일/국방, label: 정치개혁\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 정치개혁, label: 미래\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 정치개혁, label: 안전/환경\n",
      "logits: 정치개혁, label: 일자리\n",
      "logits: 육아/교육, label: 행정\n",
      "logits: 정치개혁, label: 안전/환경\n",
      "logits: 정치개혁, label: 행정\n",
      "logits: 외교/통일/국방, label: 외교/통일/국방\n",
      "logits: 정치개혁, label: 미래\n",
      "logits: 정치개혁, label: 일자리\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 정치개혁, label: 보건복지\n",
      "logits: 정치개혁, label: 보건복지\n",
      "logits: 외교/통일/국방, label: 안전/환경\n",
      "logits: 정치개혁, label: 일자리\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 정치개혁, label: 일자리\n",
      "logits: 보건복지, label: 안전/환경\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 보건복지, label: 저출산/고령화대책\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 외교/통일/국방, label: 미래\n",
      "logits: 정치개혁, label: 미래\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 정치개혁, label: 외교/통일/국방\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 정치개혁, label: 외교/통일/국방\n",
      "logits: 정치개혁, label: 행정\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 육아/교육, label: 저출산/고령화대책\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 정치개혁, label: 저출산/고령화대책\n",
      "logits: 보건복지, label: 농산어촌\n",
      "logits: 정치개혁, label: 미래\n",
      "logits: 정치개혁, label: 미래\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 안전/환경, label: 정치개혁\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 정치개혁, label: 보건복지\n",
      "logits: 외교/통일/국방, label: 외교/통일/국방\n",
      "logits: 외교/통일/국방, label: 외교/통일/국방\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 육아/교육, label: 미래\n",
      "logits: 정치개혁, label: 외교/통일/국방\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 정치개혁, label: 육아/교육\n",
      "logits: 보건복지, label: 일자리\n",
      "logits: 안전/환경, label: 보건복지\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 정치개혁, label: 농산어촌\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 정치개혁, label: 성장동력\n",
      "logits: 정치개혁, label: 행정\n",
      "logits: 정치개혁, label: 성장동력\n",
      "logits: 외교/통일/국방, label: 안전/환경\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 육아/교육, label: 일자리\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 정치개혁, label: 외교/통일/국방\n",
      "logits: 정치개혁, label: 육아/교육\n",
      "logits: 정치개혁, label: 일자리\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 정치개혁, label: 미래\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "logits: 안전/환경, label: 정치개혁\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 육아/교육, label: 안전/환경\n",
      "logits: 정치개혁, label: 일자리\n",
      "logits: 보건복지, label: 보건복지\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 외교/통일/국방, label: 외교/통일/국방\n",
      "logits: 안전/환경, label: 안전/환경\n",
      "logits: 육아/교육, label: 일자리\n",
      "logits: 일자리, label: 일자리\n",
      "logits: 정치개혁, label: 정치개혁\n",
      "logits: 육아/교육, label: 육아/교육\n",
      "Result: 49%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "trainedNN = NeuralNetwork(len(word2index), len(targets2index), 0.001)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './train_1000.ckpt')\n",
    "\n",
    "    cnt = 0\n",
    "    print(\"Validation\")\n",
    "    for i in range(len(numbers)-100, len(numbers)):\n",
    "        inputs = np.zeros(len(word2index))\n",
    "        for word in contents[i]:\n",
    "            inputs[word2index[word]] = 1.0\n",
    "            \n",
    "        output = sess.run([trainedNN.output], feed_dict={trainedNN.inputs: inputs.reshape(-1, len(word2index))})\n",
    "        index = np.argmax(output)\n",
    "        #print('output: {}, index: {}'.format(output, index))\n",
    "        if list(targets2index)[index] == categories[i]:\n",
    "            cnt += 1\n",
    "        \n",
    "        print(\"logits: {}, label: {}\".format(list(targets2index)[index], categories[i]))\n",
    "    print(\"Result: {}%\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
